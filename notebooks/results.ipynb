{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import sys \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torchvision\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data1 =pd.read_csv('/home/juan/Documents/Master_Project/data/process/final_selection/datasets_to_choose/data1.csv')\n",
    "data9 = pd.read_csv('/home/juan/Documents/Master_Project/data/process/final_selection/datasets_to_choose/data_1_test.csv')\n",
    "\n",
    "df_1 = data1.iloc[:, 1:]\n",
    "df_9 = data9.iloc[:,1:]\n",
    "\n",
    "# Iterate through each DataFrame and merge 'internal_vdw' column from df_9\n",
    "df_1 = pd.merge(df_1, df_9[['Folder', 'internal_vdw_energy']], on='Folder', how='inner')\n",
    "\n",
    "columns = df_1.columns.tolist()\n",
    "\n",
    "# Remove \"Folder\" and \"QM/MM SP Barrier\" from the list of columns\n",
    "columns.remove(\"Folder\")\n",
    "columns.remove(\"QM/MM SP Barrier\")\n",
    "\n",
    "# Reorder the list of columns with \"Folder\" and \"QM/MM SP Barrier\" at the end\n",
    "new_columns_order = columns + [\"Folder\", \"QM/MM SP Barrier\"]\n",
    "\n",
    "# Reindex the DataFrame to reorder the columns\n",
    "df_1 = df_1.reindex(columns=new_columns_order)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_initial = pd.read_csv('/home/juan/Documents/Master_Project/data/process/initial/dataset.csv')\n",
    "df = dataset_initial.iloc[:,1:]\n",
    "data_all = pd.read_csv('/home/juan/Documents/Master_Project/data/process/dataset_ext_ALLB.csv')\n",
    "df0 = data_all[df.columns]\n",
    "df_0 = df0.merge(df_1[['Folder']], on='Folder', how='inner')\n",
    "df_0.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_initial = pd.read_csv('/home/juan/Documents/Master_Project/data/process/initial/dataset.csv')\n",
    "df00 = dataset_initial.iloc[:,1:]\n",
    "df00\n",
    "df00.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/juan/Documents/Master_Project/data/process/final_selection/All_feats_newC_hp_atoms.csv')\n",
    "df = df.iloc[:, 1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import your custom TorchRandomForestRegressor\n",
    "import sys\n",
    "sys.path.append('/home/juan/Documents/Master_Project/code/my_work/Testing-Algorithms/')\n",
    "from rf_improved2_copy import TorchRandomForestRegressor\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from tqdm import tqdm\n",
    "def mean_deviation_from_true_mean(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean of the absolute deviations of predicted values from the mean of true values.\n",
    "\n",
    "    :param y_true: array-like, true values.\n",
    "    :param y_pred: array-like, predicted values.\n",
    "    :return: float, mean deviation from the true mean.\n",
    "    \"\"\"\n",
    "    true_mean = np.mean(y_true)\n",
    "    deviations = np.abs(y_pred - true_mean)\n",
    "    mean_deviation = np.mean(deviations)\n",
    "    return mean_deviation\n",
    "\n",
    "def preprocess_data_manual_no_split(df, use_torch):\n",
    "    X = df.drop(columns=['QM/MM SP Barrier', 'Folder']).values\n",
    "    Y = df['QM/MM SP Barrier'].values\n",
    "    ss = StandardScaler()\n",
    "    Y_reshaped = Y.reshape(-1, 1)\n",
    "    Y_normalized = ss.fit_transform(Y_reshaped)\n",
    "    if use_torch:\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        Y_normalized = torch.tensor(Y_normalized, dtype=torch.float32).flatten()\n",
    "    return X, Y_normalized, ss\n",
    "\n",
    "\n",
    "def cross_validate_with_blind_set(X, y,feature_names, X_blind, y_blind=None, n_splits=10, use_torch=False):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    pearson_corr_scores = []\n",
    "    deviations = []\n",
    "    feature_importances = {name: [] for name in feature_names}  # Initialize feature importance dictionary\n",
    "\n",
    "    # Suppress DataConversionWarnings\n",
    "    warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "    \n",
    "    # Initialize model\n",
    "    if use_torch:\n",
    "        model = TorchRandomForestRegressor(nb_trees=8, nb_samples=40, max_depth=200, bootstrap=True)\n",
    "    else:\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=160,\n",
    "            criterion=\"squared_error\",\n",
    "            max_depth=30,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=0.8,\n",
    "            bootstrap=True,\n",
    "            oob_score=True,\n",
    "            n_jobs=-1,\n",
    "            random_state=40,\n",
    "            ccp_alpha=0.00,\n",
    "            max_samples=None,\n",
    "            monotonic_cst=None)\n",
    "        '''\n",
    "        svr_model = SVR(kernel='rbf',        # Non-linear kernel\n",
    "                degree=3,            # Degree for the polynomial kernel. Irrelevant for the 'rbf' kernel.\n",
    "                gamma='scale',       # Gamma value of 'scale' accounts for the number of features automatically.\n",
    "                coef0=0.0,           # Independent term in kernel function, significant only in 'poly' and 'sigmoid'.\n",
    "                tol=1e-3,            # Tolerance for stopping criterion.\n",
    "                C=1.0,               # Regularization parameter.\n",
    "                epsilon=0.1,         # Epsilon in the epsilon-SVR model.\n",
    "                shrinking=True,      # Whether to use the shrinking heuristic.\n",
    "                cache_size=200,      # Specify the size of the kernel cache (in MB).\n",
    "                verbose=False,       # Enable verbose output.\n",
    "                max_iter=-1)         # Hard limit on iterations within solver, or -1 for no limit.'''\n",
    "\n",
    "    \n",
    "    # Use tqdm for progress display\n",
    "    for train_index, test_index in tqdm(kf.split(X), total=n_splits, desc=\"Cross-Validation\"):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Ensure y_train is properly shaped for RandomForestRegressor\n",
    "        y_train = y_train.ravel() if not use_torch else y_train\n",
    "\n",
    "        # Fit the model\n",
    "        if use_torch:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Ensure y_pred and y_test are flattened\n",
    "        y_pred = y_pred.flatten() if hasattr(y_pred, 'flatten') else y_pred.view(-1)\n",
    "        y_test = y_test.flatten() if hasattr(y_test, 'flatten') else y_test.view(-1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "        pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "        pearson_corr_scores.append(pearson_corr)\n",
    "        deviation = mean_deviation_from_true_mean(y_test, y_pred)\n",
    "        deviations.append(deviation)\n",
    "    # Restore warning behavior to default\n",
    "    warnings.filterwarnings(action='default', category=DataConversionWarning)\n",
    "\n",
    "    # Prepare for blind set prediction\n",
    "    if use_torch:\n",
    "        blind_set_predictions = model.predict(X_blind).flatten()  # Ensure it's flattened\n",
    "    else:\n",
    "        blind_set_predictions = model.predict(X_blind)\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "    for name, importance in zip(feature_names, importances):\n",
    "        feature_importances[name].append(importance)\n",
    "    \n",
    "    # Unstandardize predictions and actuals for plotting\n",
    "    blind_set_rmse = None\n",
    "    blind_pearson_corr = None\n",
    "    if y_blind is not None:\n",
    "        y_blind = y_blind.flatten()  # Ensure y_blind is flattened\n",
    "        blind_set_rmse = np.sqrt(mean_squared_error(y_blind, blind_set_predictions))\n",
    "        blind_pearson_corr, _ = pearsonr(y_blind, blind_set_predictions)\n",
    "\n",
    "    return np.mean(rmse_scores), np.mean(pearson_corr_scores), np.mean(deviations), blind_set_predictions, blind_set_rmse, blind_pearson_corr, feature_importances\n",
    "\n",
    "def plot_actual_vs_predicted(Y_actual, Y_predicted, pearson_corr, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(Y_actual, Y_predicted, color='Tomato', alpha=0.5)\n",
    "    plt.plot(Y_actual, Y_actual, color='SteelBlue')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Actual Barriers')\n",
    "    plt.ylabel('Predicted Barriers')\n",
    "    plt.text(0.05, 0.95, f'Pearson Correlation: {pearson_corr:.3f}', transform=plt.gca().transAxes, fontsize=12,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "    plt.show()\n",
    "\n",
    "def complete_analysis_pipeline(df, title, use_torch=False):\n",
    "    X, Y_normalized, ss = preprocess_data_manual_no_split(df, use_torch)\n",
    "    # Splitting the dataset into training and blind sets\n",
    "    train_percentage = 0.65\n",
    "    n_samples = len(X)\n",
    "    n_train_samples = int(train_percentage * n_samples)\n",
    "    X_train, Y_train = X[:n_train_samples], Y_normalized[:n_train_samples]\n",
    "    X_blind, Y_blind = X[n_train_samples:], Y_normalized[n_train_samples:]\n",
    "    print(len(X_blind), len(Y_blind))\n",
    "    mean_rmse, mean_pearson, mean_deviationn, blind_set_predictions, blind_set_rmse, blind_pearson_corr, feature_importances = cross_validate_with_blind_set(X_train, Y_train, X_blind, Y_blind, use_torch=use_torch)\n",
    "    \n",
    "    # Unstandardize predictions and actuals for plotting\n",
    "    blind_true = ss.inverse_transform(Y_blind.reshape(-1, 1)).flatten()\n",
    "    blind_pred = ss.inverse_transform(blind_set_predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "    print(f\"Mean RMSE: {mean_rmse}, Mean Pearson Correlation: {mean_pearson}, Blind Set RMSE: {blind_set_rmse}, Blind Pearson Correlation: {blind_pearson_corr}, Deviation: {mean_deviationn}\")\n",
    "    plot_actual_vs_predicted(blind_true, blind_pred, blind_pearson_corr, title)\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_initial = pd.read_csv('/home/juan/Documents/Master_Project/data/process/initial/dataset.csv')\n",
    "df = dataset_initial.iloc[:,1:]\n",
    "data_all = pd.read_csv('/home/juan/Documents/Master_Project/data/process/dataset_ext_ALLB.csv')\n",
    "df = data_all[df.columns]\n",
    "\n",
    "data_multiv = pd.read_csv('/home/juan/Documents/Master_Project/data/process/dataset-09-03.csv')\n",
    "df2 = data_multiv.iloc[:,1:]\n",
    "\n",
    "lasso_rf = pd.read_csv('/home/juan/Documents/Master_Project/data/interim/lasso-rf-10-03.csv')\n",
    "df3 = lasso_rf.iloc[:,1:]\n",
    "\n",
    "\n",
    "data_multivariate = pd.read_csv('/home/juan/Documents/Master_Project/data/process/best_feats_multivariate.csv')\n",
    "df4 = data_multivariate.iloc[:,1:]\n",
    "\n",
    "data_simple = pd.read_csv('/home/juan/Documents/Master_Project/data/process/data_simple_featsS.csv')\n",
    "df5 = data_simple.iloc[:,1:]\n",
    "\n",
    "df6 = pd.read_csv('/home/juan/Documents/Master_Project/data/interim/data_simple_feats_MF.csv')\n",
    "df6.head() \n",
    "df6 = df6.iloc[:,1:]\n",
    "dff = pd.read_csv('/home/juan/Documents/Master_Project/data/interim/forces.csv')\n",
    "dff= dff.iloc[:,1:]\n",
    "merged_df = pd.merge(df6, dff, on='Folder', how='inner')\n",
    "merged_df = merged_df[[col for col in merged_df.columns if col not in ['Folder', 'QM/MM SP Barrier']] + ['Folder', 'QM/MM SP Barrier']]\n",
    "df_final =pd.read_csv('/home/juan/Documents/Master_Project/data/process/final_selection/all_data_simple_selection.csv')\n",
    "df_final=df_final.iloc[:,1:]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_big_outliers(df, column_name, threshold):\n",
    "    \"\"\"\n",
    "    Remove values greater than a specified threshold from a specific column in the DataFrame.\n",
    "\n",
    "    :param df: DataFrame containing the data\n",
    "    :param column_name: Name of the column to remove outliers from\n",
    "    :param threshold: Threshold value for removing outliers\n",
    "    :return: DataFrame with outliers removed\n",
    "    \"\"\"\n",
    "    # Remove rows with values greater than the threshold from the specified column\n",
    "    df_no_outliers = df[df[column_name] <= threshold]\n",
    "    \n",
    "    return df_no_outliers\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df_final is your DataFrame containing data\n",
    "# Remove values greater than 40 from the column \"QM/MM SP Barrier\"\n",
    "column_name = \"QM/MM SP Barrier\"\n",
    "threshold = 40\n",
    "df_no_outliers = remove_big_outliers(df_final, column_name, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df3.drop(columns=['QM/MM SP Barrier', 'Folder'])  # Features\n",
    "y = df3['QM/MM SP Barrier']  # Target variable\n",
    "\n",
    "def manual_train_test_split(X, y, test_size=0.6, random_state=None):\n",
    "    \"\"\"\n",
    "    Manually splits the dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        X (array-like): The feature matrix.\n",
    "        y (array-like): The target variable.\n",
    "        test_size (float or int): The proportion of the dataset to include in the test split.\n",
    "            If float, should be between 0.0 and 1.0.\n",
    "            If int, represents the absolute number of test samples.\n",
    "        random_state (int or None): Random seed for reproducibility. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        array-like: The training features (X_train).\n",
    "        array-like: The testing features (X_test).\n",
    "        array-like: The training target (y_train).\n",
    "        array-like: The testing target (y_test).\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle the indices of the dataset\n",
    "    n_samples = len(X)\n",
    "    shuffled_indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    # Calculate the number of samples for the test set\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = int(test_size * n_samples)\n",
    "    \n",
    "    # Split the shuffled indices into training and testing indices\n",
    "    test_indices = shuffled_indices[:test_size]\n",
    "    train_indices = shuffled_indices[test_size:]\n",
    "    \n",
    "    # Create the training and testing sets\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example usage\n",
    "# Assuming X and y are your feature matrix and target variable, respectively\n",
    "X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_features='sqrt', max_depth=80, \n",
    "                                      min_samples_split=2, min_samples_leaf=2, bootstrap=True, \n",
    "                                      n_jobs=-1, verbose=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on training and testing sets\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Plot training set\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_train, y_train_pred, color='blue', label='Training set')\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Training Set: True vs Predicted Values (MSE = {:.2f})'.format(train_mse))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot testing set\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, color='green', label='Testing set')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Testing Set: True vs Predicted Values (MSE = {:.2f})'.format(test_mse))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot both training and testing sets on one plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot training set\n",
    "plt.scatter(y_train, y_train_pred, color='lightblue', label='Training set', alpha=0.8)\n",
    "\n",
    "# Plot testing set\n",
    "plt.scatter(y_test, y_test_pred, color='darkorange', label='Testing set', alpha=0.2)\n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_initial = pd.read_csv('/home/juan/Documents/Master_Project/data/process/initial/dataset.csv')\n",
    "df = dataset_initial.iloc[:,1:]\n",
    "data_all = pd.read_csv('/home/juan/Documents/Master_Project/data/process/dataset_ext_ALLB.csv')\n",
    "df0 = data_all[df.columns]\n",
    "# Merge df_0 with df_1 based on the 'Folder' column\n",
    "df_0 = df0.merge(df_1[['Folder']], on='Folder', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df,title='  ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df00,title='  ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df_9,title='  ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df_0,title='  ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df_1,title='  ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df_no_outliers,title='  ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df,title='  ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df2,title='', use_torch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df3,title=' ', use_torch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df4,title='', use_torch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df5,title='', use_torch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(df6,title='', use_torch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_analysis_pipeline(merged_df,title='', use_torch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def manual_train_test_split(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Manually split the dataset into training and testing sets.\n",
    "    \n",
    "    :param X: Features (numpy array).\n",
    "    :param y: Target variable (numpy array).\n",
    "    :param test_size: Proportion of the dataset to include in the test split.\n",
    "    :return: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Determine the number of data points\n",
    "    num_data = X.shape[0]\n",
    "    \n",
    "    # Shuffle the data indices\n",
    "    indices = np.arange(num_data)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split indices for training and testing\n",
    "    split_idx = int(num_data * (1 - test_size))\n",
    "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "    \n",
    "    # Create the training and testing sets\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "x,y,ss = preprocess_data_manual_no_split(df6, use_torch=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = manual_train_test_split(x, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer with Dropout\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Second LSTM Layer\n",
    "    model.add(LSTM(128, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Dense Layer for prediction\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Use 'sigmoid' for binary classification, 'softmax' for multi-class\n",
    "\n",
    "    return model\n",
    "\n",
    "# Assuming X_train is your input features with shape (n_samples, seq_length, n_features)\n",
    "# For gene expression data, seq_length would typically be 1, making this a typical dense network layout.\n",
    "X_train_reshaped = np.expand_dims(X_train, axis=1) # This will make the shape (num_samples, 1, num_features)\n",
    "input_shape = (1, X_train.shape[1])\n",
    "\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',  # 'categorical_crossentropy' for multi-class\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "# Assuming the rest of your code remains the same\n",
    "history = model.fit(X_train_reshaped, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=64, \n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "# Note: You should also include callbacks like ModelCheckpoint and EarlyStopping for better training control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_analysis_pipeline(df, title, use_torch=False):\n",
    "    feature_names = df.drop(columns=['QM/MM SP Barrier', 'Folder']).columns.tolist()\n",
    "    X, Y_normalized, ss = preprocess_data_manual_no_split(df, use_torch)\n",
    "    \n",
    "    # Splitting the dataset into training and blind sets\n",
    "    train_percentage = 0.65\n",
    "    n_samples = len(X)\n",
    "    n_train_samples = int(train_percentage * n_samples)\n",
    "    X_train, Y_train = X[:n_train_samples], Y_normalized[:n_train_samples]\n",
    "    X_blind, Y_blind = X[n_train_samples:], Y_normalized[n_train_samples:]\n",
    "\n",
    "    mean_rmse, mean_pearson, mean_deviation, blind_set_predictions, blind_set_rmse, blind_pearson_corr, feature_importances = cross_validate_with_blind_set(X_train, Y_train, X_blind, Y_blind, use_torch=use_torch, feature_names=feature_names)\n",
    "    \n",
    "    # Unstandardize predictions and actuals for plotting\n",
    "    blind_true = ss.inverse_transform(Y_blind.reshape(-1, 1)).flatten()\n",
    "    blind_pred = ss.inverse_transform(blind_set_predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "    print(f\"Mean RMSE: {mean_rmse}, Mean Pearson Correlation: {mean_pearson}, Blind Set RMSE: {blind_set_rmse}, Blind Pearson Correlation: {blind_pearson_corr}, Deviation: {mean_deviation}\")\n",
    "    for feature, importances in feature_importances.items():\n",
    "        print(f\"{feature}: {np.mean(importances)}\")\n",
    "    plot_actual_vs_predicted(blind_true, blind_pred, blind_pearson_corr, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_analysis_pipeline(df, title, use_torch=False):\n",
    "    feature_names = df.drop(columns=['QM/MM SP Barrier', 'Folder']).columns.tolist()\n",
    "    X, Y_normalized, ss = preprocess_data_manual_no_split(df, use_torch)\n",
    "    \n",
    "    # Splitting the dataset into training and blind sets\n",
    "    train_percentage = 0.65\n",
    "    n_samples = len(X)\n",
    "    n_train_samples = int(train_percentage * n_samples)\n",
    "    X_train, Y_train = X[:n_train_samples], Y_normalized[:n_train_samples]\n",
    "    X_blind, Y_blind = X[n_train_samples:], Y_normalized[n_train_samples:]\n",
    "\n",
    "    mean_rmse, mean_pearson, mean_deviation, blind_set_predictions, blind_set_rmse, blind_pearson_corr, feature_importances = cross_validate_with_blind_set(X_train, Y_train, feature_names,  X_blind, Y_blind, use_torch=use_torch)\n",
    "    \n",
    "    # Unstandardize predictions and actuals for plotting\n",
    "    blind_true = ss.inverse_transform(Y_blind.reshape(-1, 1)).flatten()\n",
    "    blind_pred = ss.inverse_transform(blind_set_predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "    print(f\"Mean RMSE: {mean_rmse}, Mean Pearson Correlation: {mean_pearson}, Blind Set RMSE: {blind_set_rmse}, Blind Pearson Correlation: {blind_pearson_corr}, Deviation: {mean_deviation}\")\n",
    "    for feature, importances in feature_importances.items():\n",
    "        print(f\"{feature}: {np.mean(importances)}\")\n",
    "    plot_actual_vs_predicted(blind_true, blind_pred, blind_pearson_corr, title)\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2 = complete_analysis_pipeline(df, ' ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = complete_analysis_pipeline(df_9, ' ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the feature_importances to organize by training rather than by feature\n",
    "trainings_transposed = list(zip(*feats.values()))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(50, 20))  # Further increased figure size for clarity\n",
    "for i, training in enumerate(trainings_transposed):\n",
    "    plt.plot(list(feats.keys()), training, marker='o', label=f'Training {i+1}')\n",
    "\n",
    "plt.title('Feature Importances Across Trainings', fontsize=30)  # Further increased title font size\n",
    "plt.xlabel('Features', fontsize=24)  # Further increased x-axis label font size\n",
    "plt.ylabel('Importance', fontsize=24)  # Further increased y-axis label font size\n",
    "plt.xticks(rotation=90, fontsize=19)  # Rotated to 90 degrees and decreased font size\n",
    "plt.yticks(fontsize=20)  # Further increased y-axis tick label font size\n",
    "plt.legend(fontsize=20, loc='upper right')  # Increased legend font size and moved to avoid blocking the plot\n",
    "plt.subplots_adjust(bottom=0.5)  # Adjusted bottom spacing to accommodate rotated x labels\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'feats' is a dictionary with feature names as keys and lists of importances as values\n",
    "\n",
    "# Filter out features with zero importance across all trainings\n",
    "non_zero_feats = {feature: importances for feature, importances in feats.items() if any(importance > 0 for importance in importances)}\n",
    "\n",
    "# Transpose the feature_importances to organize by training rather than by feature\n",
    "trainings_transposed = list(zip(*feats.values()))\n",
    "feature_names = list(feats.keys())\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, len(feature_names) * 0.3))  # Adjusted vertical size based on the number of features\n",
    "for i, training in enumerate(trainings_transposed):\n",
    "    plt.plot(training, range(len(feature_names)), marker='o', linestyle='-', label=f'Training {i+1} Fold')\n",
    "\n",
    "plt.title('Feature Importances Across Trainings', fontsize=20)\n",
    "plt.xlabel('Importance', fontsize=16)\n",
    "plt.yticks(range(len(feature_names)), feature_names, fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(True, axis='x')\n",
    "\n",
    "# Improve layout and spacing\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis so the features are listed top-down\n",
    "plt.subplots_adjust(left=0.2, bottom=0.1, top=0.95)  # Adjust spacing to accommodate feature names and titles\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the feature_importances to organize by training rather than by feature\n",
    "trainings_transposed = list(zip(*feats.values()))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 50))  # Adjusted figure size for vertical orientation\n",
    "for i, training in enumerate(trainings_transposed):\n",
    "    plt.barh(range(len(list(feats.keys()))), training, label=f'Training {i+1}')\n",
    "\n",
    "plt.title('Feature Importances Across Trainings', fontsize=30)  # Adjusted title font size\n",
    "plt.ylabel('Features', fontsize=24)  # Adjusted y-axis label (now for features) font size\n",
    "plt.xlabel('Importance', fontsize=24)  # Adjusted x-axis label (now for importances) font size\n",
    "plt.yticks(range(len(list(feats.keys()))), list(feats.keys()), fontsize=12)  # Adjusted feature name font size\n",
    "plt.xticks(fontsize=20)  # Adjusted importance value font size\n",
    "plt.legend(fontsize=20, loc='lower right')  # Adjusted legend font size and location\n",
    "plt.tight_layout()\n",
    "plt.grid(True)  # Added grid for better readability of values\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featsT = complete_analysis_pipeline(df, ' ', use_torch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average importance for each feature\n",
    "average_importances = {feature: np.mean(importances) for feature, importances in featsT.items()}\n",
    "\n",
    "# Identify the threshold for the top 10% features based on average importance\n",
    "threshold_value = np.quantile(list(average_importances.values()), 0.90)\n",
    "\n",
    "# Select only the top 10% features based on the threshold, maintaining their original order\n",
    "top_featsT = {feature: importances for feature, importances in featsT.items() if average_importances[feature] >= threshold_value}\n",
    "\n",
    "# Since we want to plot all trainings without ordering the features by importance, \n",
    "# we maintain the original feature ordering but limit to top 10% features\n",
    "selected_features = [feature for feature in featsT if feature in top_featsT]\n",
    "\n",
    "# Calculate the average importance of the selected top 10% features for plotting\n",
    "average_top_importances = [np.mean(featsT[feature]) for feature in selected_features]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 24))  # Adjust the figure size to better fit the vertical orientation\n",
    "plt.barh(selected_features, average_top_importances, color='slateblue')\n",
    "\n",
    "plt.title('Average Importances of Top 10% Features Across All Trainings', fontsize=20)  # Increase title font size\n",
    "plt.xlabel('Average Importance', fontsize=16)  # Increase x-axis label font size\n",
    "plt.ylabel('Features', fontsize=16)  # Increase y-axis label font size\n",
    "plt.xticks(fontsize=14)  # Increase x-axis tick font size\n",
    "plt.yticks(fontsize=14)  # Increase y-axis tick font size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average importance for each feature\n",
    "average_importances = {feature: np.mean(importances) for feature, importances in featsT.items()}\n",
    "\n",
    "# Identify the threshold for the top 10% features based on average importance\n",
    "threshold_value = np.quantile(list(average_importances.values()), 0.90)\n",
    "\n",
    "# Select only the top 10% features based on the threshold, maintaining their original order\n",
    "top_featsT = {feature: importances for feature, importances in featsT.items() if average_importances[feature] >= threshold_value}\n",
    "\n",
    "# Define criteria for identifying newly added features:\n",
    "# A feature is considered 'newly added' if it doesn't represent an entire number and\n",
    "# starts with \"resid\" or \"resname\".\n",
    "def is_new_feature(feature):\n",
    "    return not feature.isdigit() or (feature.startswith('resid') or feature.startswith('resname'))\n",
    "\n",
    "# Filter the top 10% features to find those that are newly added\n",
    "newly_added_top_features = [feature for feature in top_featsT if is_new_feature(feature)]\n",
    "\n",
    "# Calculate the percentage of newly added features in the top 10%\n",
    "percentage_new_features = (len(newly_added_top_features) / len(top_featsT)) * 100\n",
    "\n",
    "print(f\"Percentage of newly added features in the top 10%: {percentage_new_features:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Proportion of features added by you within the top 10%\n",
    "features_added_by_you = 68.85\n",
    "features_not_added_by_you = 100 - 68.85\n",
    "\n",
    "# Pie chart labels and sizes\n",
    "labels = ['New Features', 'Initial Features']\n",
    "sizes = [features_added_by_you, features_not_added_by_you]\n",
    "\n",
    "# Colors for the pie chart slices\n",
    "colors = ['slateblue', 'skyblue']  # Adjusted to match your preference\n",
    "\n",
    "# Create subplots\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the pie chart\n",
    "wedges, texts, autotexts = ax1.pie(sizes, colors=colors, labels=labels, autopct='%1.1f%%', startangle=0)\n",
    "\n",
    "# Draw a circle at the center\n",
    "centre_circle = plt.Circle((0, 0), 0.80, fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Set text size for labels and percentages\n",
    "for text in texts:\n",
    "    text.set_fontsize(17)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontsize(17)\n",
    "\n",
    "\n",
    "# Aspect ratio and layout\n",
    "ax1.axis('equal')  \n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average importance for each feature\n",
    "average_importances = {feature: np.mean(importances) for feature, importances in featsT.items()}\n",
    "\n",
    "# Sort features by their average importance in descending order and select the top 20\n",
    "top_features = sorted(average_importances.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "# Extracting just the feature names for the selected top 20 features\n",
    "selected_features = [feature for feature, _ in top_features]\n",
    "\n",
    "# Extracting the average importances for the selected top 20 features for plotting\n",
    "average_top_importances = [average_importances[feature] for feature in selected_features]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 10))  # Adjust the figure size for a clear view of the top 20 features\n",
    "plt.bar(selected_features, average_top_importances, color='slateblue')\n",
    "\n",
    "plt.ylabel('Average Importance', fontsize=21)  # Adjust for vertical orientation\n",
    "plt.xticks(rotation=80, fontsize=19)  # Rotate feature names for clarity\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average importance for each feature\n",
    "average_importances = {feature: np.mean(importances) for feature, importances in featsT.items()}\n",
    "\n",
    "# Sort features by their average importance in descending order and select the top 30\n",
    "top_features = sorted(average_importances.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "# Extracting just the feature names for the selected top 30 features\n",
    "selected_features = [feature for feature, _ in top_features]\n",
    "\n",
    "# Extracting the average importances for the selected top 30 features for plotting\n",
    "average_top_importances = [average_importances[feature] for feature in selected_features]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 15))  # Adjust the figure size for a clear view of the top 30 features\n",
    "plt.barh(selected_features[::-1], average_top_importances[::-1], color='slateblue')  # Reverse the lists to have the highest on top\n",
    "\n",
    "plt.title('Average Importances of Top 20 Features Across All Trainings', fontsize=25)\n",
    "plt.xlabel('Average Importance', fontsize=21)\n",
    "plt.xticks(fontsize=19)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
